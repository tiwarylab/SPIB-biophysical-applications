[Model Parameters]
# Time delay delta t in terms of # of minimal time resolution of the trajectory data
dt = [10]

# Dimension of RC or bottleneck
d = [1]

# Encoder type (Linear or Nonlinear)
encoder_type = Nonlinear

# Number of nodes in each hidden layer of the encoder
neuron_num1 = [32]

# Number of nodes in each hidden layer of the decoder
neuron_num2 = [1048]


[Training Parameters]

batch_size = 256

# Threshold in terms of the change of the predicted state population for measuring the convergence of training 
threshold = 0.02

# Number of epochs with the change of the state population smaller than the threshold after which this iteration of training finishes
patience = 2

# Minimum refinements
min_refinements = 20

# Period of learning rate decay
lr_scheduler_step_size = 2

# Multiplicative factor of learning rate decay. Default: 1 (No learning rate decay)
lr_scheduler_gamma = 1.00

# By default, we save the model every 10000 steps
log_interval = 10000

# Initial learning rate of Adam optimizer
learning_rate = [0.000005]

# Hyper-parameter beta
beta = [0.001]

[Data]
# Path to the trajectory data
traj_data = [../drug_unbiased/traj_all_low_res_100_25ns_plus_z.npy,../drug_unbiased/traj_all_low_res_100_25ns_minus_z.npy]
# For mulitple trajectroies, traj_data = [path to traj0 data, path to traj1 data, path to traj2 data]

# Path to the initial state labels
initial_labels = [../drug_unbiased/init_labels_plus.npy,../drug_unbiased/init_labels_minus.npy]
# For mulitple trajectroies, initial_labels = [path to traj0 labels, path to traj1 labels, path to traj2 labels]

# Path to the weights of the samples, by default all the samples have the same weights
traj_weights 
# For mulitple trajectroies, traj_weights = [path to traj0 weights, path to traj1 weights, path to traj2 weights]


[Other Controls]
# Random seed
seed = [100]

# Whether to refine the labels during the training process
UpdateLabel = True

# Whether save trajectory results
SaveTrajResults = True
